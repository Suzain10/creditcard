# -*- coding: utf-8 -*-
"""CreditCard_Fraud_Detection.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1M_YLQkDCB2oww7dGQr32Coyg-QTddQIm
"""

import numpy as np
import pandas as pd
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import recall_score, precision_score, average_precision_score, accuracy_score, f1_score
from sklearn.neural_network import MLPClassifier
from imblearn.over_sampling import SMOTE

np.random.seed(1)

# Load your dataset
data = pd.read_csv('creditcard.csv')

# Handle missing values (if any)
data = data.dropna()

# Normalize the 'Amount' feature
data['normAmount'] = StandardScaler().fit_transform(data['Amount'].values.reshape(-1, 1))
data = data.drop(['Time', 'Amount'], axis=1)

# Define features and target
X = data.iloc[:, data.columns != 'Class']
y = data.iloc[:, data.columns == 'Class'].values.ravel()

# Handle class imbalance using SMOTE
smote = SMOTE(random_state=42, k_neighbors=2)  # Set k_neighbors to a smaller value
X_resampled, y_resampled = smote.fit_resample(X, y)

# Split the resampled data into training and test sets
X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.3, random_state=0, stratify=y_resampled)

# Define and train the MLPClassifier with chosen parameters
mlp = MLPClassifier(hidden_layer_sizes=(50,), activation='tanh', solver='adam', alpha=0.0001,
                    learning_rate='constant', learning_rate_init=0.001, batch_size=64,
                    max_iter=100, early_stopping=True, random_state=42)

# Fit the model
mlp.fit(X_train, y_train)

# Predict on the test set
y_pred = mlp.predict(X_test)

# Calculate the accuracy score
accuracy = accuracy_score(y_test, y_pred)
print(f'Accuracy: {accuracy}')

# Calculate the recall score
recall_acc = recall_score(y_test, y_pred)
print(f'Recall Score: {recall_acc}')

# Calculate the precision score
precision_acc = precision_score(y_test, y_pred)
print(f'Precision Score: {precision_acc}')

# Calculate the average precision score (AUPRC)
auprc = average_precision_score(y_test, y_pred)
print(f'AUPRC: {auprc}')

# Calculate the F1 score
f1 = f1_score(y_test, y_pred)
print(f'F1 Score: {f1}')

